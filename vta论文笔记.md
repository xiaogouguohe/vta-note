# 0 摘要

- 专用深度学习加速堆栈（DL）有缺陷，不灵活
- 提出VTA
  - 通过两层ISA和一个JIT编译器来实现灵活性
  - 两层ISA基于一个task-ISA和一个microcode-ISA（微码）
    - task-ISA协调并发计算和内存任务
    - 微码ISA实现多种操作，通过张量-张量运算来实现
- 一个运行时系统
  
  - 配备JIT编译器，可以灵活地生成和执行不同种类的代码，从而有效使用VTA架构
- VTA已经继承并开源到Apache TVM中

  - Apache TVM是一种深度学习编译堆栈


  - 我们构建这样一个流程，它可以提供在设计方面的探索，来生成用户自定义的硬件框架和可以被主流学习框架利用的软件操作库
  - 通过在FPGA上不熟深度学习模型来证明我们这个方法

# 1 Introduction

- 硬件专业化是一种加速应用程序和工作负载的有力手段
- 但是，深度学习不是一个静态的领域，而是在不断变化
  - 机器学习社区会频繁改变
    - 写模型的软件
    - 它们的模型自身
    - 表述模型的语言
    - 它们操作的数据类型
- 研究主要集中在两种加速器的设计上
  - 固定功能加速器
  - 可编程加速器（领域专用加速器）
- 当前的解决方案可提供最佳性能，但无法融入不断发展的机器学习领域（硬件资源受限制）
  - 问题：为什么固定功能的加速器会受到硬件资源的限制，也就是说，可编程加速器的灵活性体现在哪里？？？为什么说为了达到最佳性能， 需要深度学习编译器，来把负载映射到硬件上？？？
- 可编程加速器利用ISA提供更大灵活性
  - 有可编程特性了，现在就要想办法达到最佳性能，就需要深度学习编译器
  - 这些加速器的自定义行为，高度依赖于透明和模块化软件堆栈的可用性

- 面临的一个挑战是，将专业创新和快速变化的机器学习软件联系起来

- 引入VTA
  - 一种经过明确编程的体系结构，与功能强大的JIT编译器和运行时配对，可以和深度学习模型一起演进，又不牺牲专业化的优势
- VTA的如下贡献
  - 可编程的加速器设计
    - 两级编程接口
      - 高级任务ISA，允许通过编译器堆栈进行显式任务调度
      - 低级微代码ISA，提供软件定义的操作灵活性
    - 可参数化
      - 可以自定义硬件内在函数，内存和数据类型，以适应后端要求
      - 什么叫做自定义硬件相关？？？
  - 一种用于异构执行的可扩展运行时系统
    - 该系统执行微代码内核的JIT编译
  - 调度自动调整平台
- 通过为两个边缘FPGA适配不同的工作负载，展示了VTA的灵活性
- fig.1
  - 使得给定的模型适应硬件后端，是谁适应谁？？？

# 2 VTA硬件软件栈预览

- 在VTA上运行端到端负载，需要完整的软件栈，来把高级模型映射到VTA公开的编程接口，这个映射是什么意思？？？映射到接口上，是否最后还是要映射到电路板上？？？
- 列出来整个VTA栈，它已经在Apache TVm深度学习编译堆栈里了
  - 深度学习框架
    - 如TensorFlow，PyTorch等等
    - TVM具有从这些深度学习框架中提取出模型的能力，这使得从框架到VTA的通用编译成为可能
  - Relay图优化器（Relay Graph Optimizer）
    - Relay是一门语言
      - 把被以前的框架和深度学习编译器使用的计算图概括成编程语言
    - 计算图是什么
      - 回想之前看过的神经网络模型
    - IR是什么
      - 中间表示层
      - 前端（深度学习框架/编程语言）到后端（硬件）的桥梁
      - 目前有很多中间表示层
  - TVM Operator Optimizer
    - 使得这样一个过程自动化：把负载调度到VTA加速器的variants（各个部分）
    - 为什么要进行调度
      - 平铺计算？？？
      - 线程并行
      - 运算符划分为多个子计算？？？
  - JIT编译和运行（从这里开始才是VTA）
    - 编译成二进制文件
    - 管理CPU和VTA之间的异构执行？？？
  - 硬件架构（3.1）
    - VTA是可参数化的加速器
    - 编译器堆栈使用两级编程接口显式编程，两级接口？？？
    - 参数化是什么？？？
    - 为什么参数化就可以把一套VTA设计定位到不同硬件？？？

# 3 VTA硬件架构和JIT Runtime

- 两个组件
  - VTA硬件体系结构
  - JIT编译器和运行时

## 3.1 硬件架构

- 架构图见fig.3
- VTA由四个模块组成
  - fetch
  - load
  - compute
  - store
- 任务流水线
  - 由上述模块定义
  - 流水线使得
    - 计算为主的负载友好
    - 内存为主的负载友好
- 模块之间通过命令队列和SRAM进行通信
- 内存访问的同步
  - 通过依赖关系队列（dependency queues）实现
  - 主要是防止写后读、读后写之类的数据冲突
- 只要依赖关系被适当管理，三阶段体系结构（负载计算存储）可用于构建任意深度的任务流水线

### 3.1.1 可参数化

- 可以修改GEMM张量（也就是矩阵乘法的那些矩阵）的形状，来影响硬件资源的利用率

  - 修改GEMM张量的输入，权重和累加器张量的形状，会直接影响要实例化的乘法器数量和SRAM端口的宽度

- 每种数据类型都可以自定义为不同精度

  - 比如权重和输入类型可以为8位或更少，累加类型可以为32位或更少

  - 这使得可以在资源受限的情况下扩展芯片的算术密度，算术密度是什么意思，是下面这个 链接吗？？？

    https://blog.csdn.net/weixin_43728590/article/details/107212069

### 3.1.2 对外暴露的任务级流水线并行性

- 任务级流水线并行化（TLPP）是VTA体系结构中的重要特性
  - 同时使用计算和内存资源，最大化它们的利用率（否则某些时候会有闲置）

- TLPP是基于访问-执行解耦的（也就是说访问和执行是不互相影响的）
  - 把任务划分成互斥的执行上下文，以便load（取出，取指）、计算、存储可以并发执行，不会互相干扰
  - 在TVM中，为了实现这样的划分，使用虚拟线程
- 为了保证解耦之后的访问-执行指令流能及时正确执行，将依赖信息编码为指令
  - 这有效地导致了内存延迟隐藏在计算绑定的工作负载上（如2d卷积）？？？
  - 内存延迟是因为，处理器（CPU）比内存的时钟周期快，导致很多个处理器时钟周期才对应上一个内存周期？？？

### 3.1.3 基于任务等级的ISA（指令集）

- VTA支持一个高层次的基于任务的ISA，它把多周期的计算和内存指令，包括LOAD、GEMM、ALU、STORE指令（fig.4），进行编码
- 四种指令分别做什么
  - LOAD和STORE指令描述了输入如何从DRAM取出来，并且存储到片上的SRAM
    - 支持对内存的交错访问，这使得可以在不修改内存布局的情况下，取出tensor tiles（矩阵的平铺？？？）
  - GEMM和ALU指令声明了微编码内核，这是基于微操作指令的
    - 微操作指令描述了数据访问的模式，这个模式定义了深度学习的操作符？？？
- 对VTA的执行流水线做如下简单描述（fig.3）
  - fetch模块从DRAM取出来任务指令，并且根据指令类型来把它们分发到相应的任务队列，这些任务队列连接着load，compute和store模块
  - load模块把DRAM的输入，权重，bias tensor tiles加载到片上内存
  - compute模块把DRAM的一个微编码内核加载到片上内存
    - 微编码内核是基于微操作的
    - 微操作描述了访问数据的模式（输入，权重和bias）
  - compute模块执行微编码内核，来实现：通过GEMM内核进行密集的线性代数运算，或通过ALU进行逻辑算术运算
  - store模块读取compute模块的结果，写回DRAM

### 3.1.4 Compute模块

- 两个函数单元对寄存器文件进行操作：张量ALU和GEMM核
- 张量ALU执行逐元素的张量（向量）操作，如加法、激活、规范化、池化任务
- GEMM核对输入和权重张量执行矩阵乘法，以实现常见的深度学习运算操作，如2D卷积、全连接层等

- GEMM核执行矩阵乘法运算的速率是，每周期执行一个输入权重矩阵的乘法
- ###
- TVM使用张量化：一种自动化方法，它将深度学习运算操作（如2d卷积）映射到固定张量硬件内在函数

### 3.1.5 微码ISA

- compute核从微操作缓存中读取指令
  - 这些指令描述了如何对数据进行计算
- fig.5详细描述了GEMM核如何对数据进行计算，这些数据存在输入、权重、累加存储器中

- 微操作不提供控制流，因此，指令需要被展开来表达可重复的数据模板？？？
- 有两种类型的计算微操作：ALU和GEMM操作
- 现在已经没有对控制流指令的需求（微操作指令不提供控制流），在此前提条件下，为了最大程度减少微操作内核的占用量，计算内核在在两层循环内执行微操作序列
  - 这个循环通过仿射函数计算每个张量寄存器的位置？？？

- 当发送到加速器时，这种压缩方法可以减少微操作的占用空间？？？





问题

1. 实现一个硬件模块的全部流程

   - 编写verilog代码

   - 怎么具体部署到硬件上？需要先排列好电路元件和线路，然后等输入？
2. FPGA是电路板？板子上的各种电路元件是否已经排列好？如果已经排列好（固定下来），就只用等待输入，这样的FPGA适用性很小，而根据这样的FPGA板写出来的verilog适用性似乎也很小？这就是“专用加速器受到硬件的很大限制”的原因吗？如果不是这个原因的话，为什么会说受到很大限制？
3. 用chisel实现和用verilog实现，是否是等价的？（和专用/可编程之间有没有必然联系）
4. 专用/可编程区别到底在哪？专用的就是写verilog在固定的板上运行，可编程的就可以在不同板子上运行吗？
5. 前端和后端分别是什么？后端是电路板？
6. Relay是一门编程语言，把计算图表示成编程语言？
7. IR是中间表示层，有很多种，Relay是其中一种？
8. TVM调度是什么意思？
9. JIT编译是编译成二进制文件？
10. 为什么说要管理CPU和VTA的异构执行？
11. 负载是什么意思？计算绑定的负载和内存绑定的负载？
13. 访问-执行解耦是什么意思？
14. 依赖信息编码为指令是什么意思？
15. 内存延迟隐藏在计算绑定的工作负载上？内存延迟是因为，处理器（CPU）比内存的时钟周期快，导致很多个处理器时钟周期才对应上一个内存周期？
16. 微操作指令不提供控制流，指令和控制流有什么关系（x86-64）？？？

16. fig.3问题
    - LOAD模块是从DRAM读取到寄存器文件，那如何执行LOAD指令，数据流向应该是什么样子，是DRAM到寄存器文件的那条蓝色箭头吗？那么要读取的地址是从哪里流向DRAM的呢（处理器架构中是地址总线，csapp）？
    - LD->CMP几个橙色的队列是什么意思？
    - 为什么需要input buffer，weight buffer，直接读取到寄存器，compute模块直接从寄存器读取不可以吗？output buffer同理，直接写回寄存器，到时候从寄存器读出来不可以吗？或者这么说，输入和权重这些东西，可不可以直接存放在DRAM，也就是内存中，因为按照c语言的a + b，应该是直接从内存中获取a和b的？（这里要结合fig.5）
    - 为什么要微码的cache，指令直接从DRAM读取不可以吗？还是说这里存的不是高层ISA而是微码ISA，二者有所不同？
17. 两级ISA，为什么会两级？fig.4是高层的ISA，一个是汇编，一个是二进制？
18. fig.5问题
    - 每个input buffer和weight buffer会取出来一个input矩阵和一个weight矩阵，扔进去GEMM进行乘法，出来一个累加矩阵，加到某个寄存器（注意一个矩阵加到一个寄存器）
    - 一条微指令的字段
    - 什么时候会调用微指令？高层指令执行到mul A, B这样的操作的时候？