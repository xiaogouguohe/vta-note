## 4.3 流水线

从 PyVTA 的硬件架构图，也就是图 4-2 中，可以看出，这样的硬件架构是有实现流水线的潜质的。而 VTA 和 PyVTA 都确实实现了三级的 加载-计算-存储 任务级流水线。在说明如何设计这个流水线之前，首先假设一下，在没有引入流水线的情况下，PyVTA 是如何实现功能的。

### 4.3.1 没有流水线的情况

从图 4-2 可以看出，一个最小的任务，是根据输入和权重，计算出输出，这也是绝大多数神经网络的工作负载。因此，这个任务执行的流程是，加载模块从 DRAM 取出输入和权重，并且加载到输入和权重缓冲区，然后计算模块从输入和权重缓冲区取出输入和权重，存到寄存器文件，并且从微指令缓存取出计算指令，根据计算指令的种类，进行 GEMM 计算或 ALU 计算，最后计算出的结果，写到输出缓冲区，由存储模块取出来，写回 DRAM。

这就是一个最小的任务的执行过程，先后经过了加载模块，计算模块和存储模块。如果没有流水线，那么整个 PyVTA 对这些任务的执行就是，执行完这个计算任务，把输出写回 DRAM 之后，再去执行下一个任务。用图来表示可以是这样的，如图 4-6



这样执行任务，显然没有最大程度地利用硬件资源，因为从图4-6中可以看出，在加载模块工作的时候，计算模块和存储模块都处于被阻塞的状态，计算模块要等到加载模块完成这次属于它的任务，并且把输入和权重写到输入和权重缓冲区，计算模块才能开始工作；同理，存储模块要等到计算模块把输出写到输出缓冲区，才能开始工作。这会使得深度学习加速器堆栈的性能大打折扣，为此我们引入流水线来最大限度地降低这种资源浪费，用图4-7来表示这个流水线的设计思路。



从图4-7中可以看出，和非流水线执行这些任务不同， 在加载模块执行任务 t，即从DRAM取输入和权重加载到输入和权重缓冲区时，计算模块可能在执行上一个任务t - 1 的一部分，等到输入和权重被加载到缓冲区时，计算模块可能也执行完了上一个任务 t - 1 中属于它的那部分工作，把结果写入输出缓冲区，于是这时的计算模块从缓冲区取出输入和权重，进行任务 t 计算；同理，计算模块执行任务 t 的时候，存储模块也不会空等，而是可能在执行任务 t - 1 的取出结果并写回DRAM这一步骤。

那么，如何衡量这个流水线对性能的提升呢？基于现有的功能，我们很难去真正观察到执行一个任务时每个模块的耗时，不过基于流水线的理论知识，我们可以大致估计流水线对性能的提高。流水线的目的就是提高吞吐量，在这里，吞吐量可以被量化单位之间内，执行任务的个数。在最理想的情况下，我们假设每个模块执行任务的延时都是相等的，那么在任务源源不断地被执行的理想情况下，这个流水线的性能就是非流水线的三倍，因为非流水线的情况下，需要三个单位时间才能执行一个任务，而引入流水线后，三个单位时间可以执行三个任务。

当然，这是非常理想化的情况，这里至少做了两个理想化的假设，一个是流水线上会有源源不断的任务送进来被执行，另一个是所有模块执行一个任务的属于它的那部分的耗时相等。第一个假设相对来说是比较符合现实情况的，因为深度学习算法往往是计算密集型的，对硬件资源的占用非常大，因此可以视为有源源不断的任务进入流水线；但是第二个假设和实际情况差别不小，实际上，在这几个模块中，计算模块的负担经常会远远比加载模块和存储模块要重，尤其是 GEMM 核执行的矩阵乘法运算，这也是符合经验的，计算往往比取址取值这些操作要耗时更多。而在加入了这个更加现实的考虑因素以后，流水线执行源源不断的任务，更有可能会是图4-8的这种情况。





从图4-8中可以看出，制约流水线性能的主要是计算模块的耗时。如果是之前每个模块耗时相等的理想化的流水线，三个单位时间内可以执行三个任务，而现在，需要五个单位时间才能执行三个任务。



既然流水线的划分是不一致的，也就是说每个模块执行任务的耗时可能是不相等的，那么模块之间就需要通信，例如加载模块需要告知计算模块，任务 t 的加载部分已经完成，输入和权重已经被加载到输入和权重缓冲区的哪个位置，计算模块在收到消息之后才能得知，应该从缓冲区的这个位置获取输入和权重进行计算，而计算模块也需要告知存储模块，应该从输出缓冲区的哪个位置获取计算结果。因此，在每个模块之间需要一个进行通信的消息队列，这在图 4-2 中也已经体现出来了。

通过之前的分析，我们已经发现，流水线的划分程度越细致，也就是流水线的深度越深，那么性能就越高。事实上情况是否真的如此？对流水线进行更细致的划分又是否合适？对于第一个问题，在流水线的深度不会太深的情况下，性能和深度的确是呈正相关的，但是也不能忽略状态存储和读取的耗时。在刚才的分析中，我们其实还做了一个理想化的假设，就是每个时钟周期的状态存储和读取的时间消耗可以忽略不计。无论是什么硬件资源执行什么任务，它都会经过若干个时钟周期，每个时钟周期都会有时钟信号，控制硬件资源加载状态寄存器，因为想要顺序执行，就要保存上个时钟周期的状态。而流水线划分越细致，这种状态的读取和存储就越频繁，因此在流水线深度足够的情况下，读取和存储状态寄存器的耗时不再可以忽略不计，在设计流水线的时候也需要考虑这一点。

而对于第二个问题，其实也有过这样的想法，既然流水线的瓶颈是计算模块，那可不可以把计算模块再划分为 GEMM 运算和 ALU 运算，从而使流水线的深度更深？这在理论上是可行的，因为 GEMM 负责矩阵运算，ALU 负责向量加法运算，这两者有各自的计算核，不会占用相同的硬件资源；而实践上也可能是一种可行的方案，但是这样会增加硬件的复杂度，在GEMM 运算核和 ALU 运算核之间要有通信队列，所以最后还是没有采用这种方案，而是采用了默认的三阶段的加载-计算-存储流水线。





